# Trabajo Pr√°ctico Final - Base de datos (Licenciatura en Ciencia de Datos)

**Participantes del proyecto:**

* Gerardo Toboso - getobosobarrios@estudiantes.unsam.edu.ar
* Gianni Bevilacqua - gbevilacqua@estudiantes.unsam.edu.ar
* Javier Spina - jaspina@estudiantes.unsam.edu.ar
* Bautista Turri - Turribautista551@gmail.com

Este proyecto corresponde al trabajo pr√°ctico final de la materia **Base de Datos** de la Lienciatura en Ciencia de Datos (1er cuatrimestre 2025). Tiene como objetivo la implementaci√≥n de un sistema anal√≠tico realista utilizando un enfoque **pol√≠glota**, combinando al menos **un motor SQL** y **un motor NoSQL**. La consigna propone el dise√±o de una arquitectura de inteligencia de negocios (BI), incluyendo un Data Warehouse y la construcci√≥n de dashboards para realizar an√°lisis de datos. El trabajo integra procesos ETL, modelado dimensional de tablas, y t√©cnicas de miner√≠a de datos, simulando un caso empresarial completo.

## üß† Nuestro caso de negocio

Somos parte del **equipo de datos** de una compa√±√≠a que desarrolla una plataforma basada en **pulseras inteligentes** para monitorear m√©tricas de salud y actividad f√≠sica, al estilo de productos como [Whoop](https://www.whoop.com/us/en/). Nuestra responsabilidad es dise√±ar la infraestructura de datos que soporte tanto el an√°lisis de negocio como el flujo de informaci√≥n constante.

Las pulseras inteligentes registran informaci√≥n biom√©trica como:

* Actividad f√≠sica
* Duraci√≥n y calidad del sue√±o
* Tiempo en reposo
* Niveles de glucosa

Adem√°s, se recolectan m√©tricas de uso de la aplicaci√≥n m√≥vil asociada:

* Tiempo de pantalla
* Interacciones con botones y formularios
* Uso de funcionalidades espec√≠ficas

## üßæ Requerimientos clave

Desde la perspectiva del √°rea de datos, se establecen los siguientes requerimientos:

* **Modelado de un Data Warehouse** con enfoque dimensional (estrella o copo de nieve).
* **Implementaci√≥n de procesos ETL** para la carga de datos provenientes de m√∫ltiples or√≠genes heterog√©neos (SQL y NoSQL).
* **Dashboard interactivo en Power BI**, con al menos 4 elementos visuales claves para la toma de decisiones.
* **Separaci√≥n modular del c√≥digo por subsistema**: operacional y anal√≠tico.

## üß± Flujo de datos del Sistema

![Flujo de datos](./img/flujo_informacion_pulseras_inteligentes.png)

El flujo de datos de la aplicaci√≥n est√° organizado en tres subsistemas principales: **Sistema Operacional**, **Data Warehouse** y **Capa de Business Inteligence**. Cada uno de estos m√≥dulos cumple una funci√≥n espec√≠fica dentro del ecosistema de datos, y est√°n conectados mediante procesos ETL desarrollados en Python.

1. **Sistema operacional**
   Este componente gestiona toda la informaci√≥n operativa relacionada a transacciones comerciales y datos brutos de aplicaci√≥n m√≥vil y sensor de la pulsera. Se encuentra conformado por dos bases de datos:

   * **Una PostgreSQL (a trav√©s de Supabase)** que registra datos de **usuarios**, **suscripciones**, **pagos** y **estados asociados**.
   * **Y otra MongoDB** que registra los datos enviados por los **sensores de la pulsera** y la **aplicaci√≥n m√≥vil**. Aqu√≠ se registran tanto 
   las m√©tricas biom√©tricas recolectadas por las pulseras como las interacciones con la aplicaci√≥n por parte de los usuarios (como tiempo de pantalla o uso de funciones).

2. **Data Warehouse**
   Los datos operacionales son procesados mediante un flujo ETL y consolidados en un **Data Warehouse**. El objetivo 
   del mismo es guardar toda la informaci√≥n hist√≥rica del negocio para luego poder ser explotada por analistas y as√≠ mejorar continuamente el producto. El mismo se encuentra alojado en una base de datos **PostgreSQL (a trav√©s de Supabase)** la cual registra dos tipos de hechos de especial inter√©s para la compa√±ia:

   * **Hechos asociados a ventas/suscripciones del producto**.
   * **Hechos asociados a usabilidad del producto**, esto hace referencia a uso de la aplicaci√≥n por parte de los usuarios y el uso de la pulsera por igual.

3. **Capa de Business Inteligence**
   Una vez que los datos est√°n consolidados en el **Data Warehouse** estos est√°n listos para ser analizados y as√≠ obtener insights valiosos sobre el producto 
   en general. Entre los puntos clave del negocio que esta capa busca cubrir est√°n:

   * An√°lisis de ventas del producto y suscripciones a lo largo del tiempo por parte de usuarios.
   * An√°lisis de usabilidad de la pulsera y aplicaci√≥n m√≥vil en tiempo real.


## üìÇ Estructura del Proyecto

```bash
pulseras_inteligentes/
‚îú‚îÄ‚îÄ sistema_operacional/           # Sistema operacional (datos transaccionales)
‚îÇ   ‚îú‚îÄ‚îÄ ingesta_sensor_mongo/      # Scripts para ingesta de datos de sensores y aplicaci√≥n m√≥vil en MongoDB
‚îÇ   ‚îî‚îÄ‚îÄ transacciones_postgres/    # Scripts para gesti√≥n de transacciones comerciales en PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ datawarehouse/                 # Data Warehouse (Hechos de ventas y usabilidad)
‚îÇ
‚îú‚îÄ‚îÄ business_inteligence/          # Capa de Business Intelligence
‚îÇ   ‚îî‚îÄ‚îÄ dashboards/                # Dashboards de Power BI
‚îÇ
‚îú‚îÄ‚îÄ utils/                         # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ conexiones_db.py           # Funciones de conexi√≥n a bases de datos
‚îÇ   ‚îî‚îÄ‚îÄ etl_funcs.py               # Funciones comunes para procesos ETL
```

## ‚öôÔ∏è Tecnolog√≠as Utilizadas

* [**PostgreSQL (via Supabase)**](https://supabase.com/) 
* [**MongoDB**](https://www.mongodb.com/) 
* [**Python (ETL y Simulaci√≥n)** ](https://www.python.org/)
* [**Power BI** ](https://www.microsoft.com/es-es/power-platform/products/power-bi)

## ‚öôÔ∏è C√≥mo clonar y correr este proyecto

### 1. Clonar el repositorio

```bash
git clone https://github.com/Gerardo1909/tp_final_pulseras_inteligentes.git
cd tp_final_pulseras_inteligentes
```

### 2. Crear y activar un entorno virtual

```bash
python -m venv venv
source venv/bin/activate      # En Linux/macOS
venv\Scripts\activate.bat     # En Windows
```

### 3. Instalar las dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar el proyecto en modo editable
Esto permite importar los m√≥dulos de `utils` desde cualquier notebook sin problemas:

```bash
pip install -e .
```



