# Trabajo Pr√°ctico Final - Base de datos (Licenciatura en Ciencia de Datos)

**Participantes del proyecto:**

* Gerardo Toboso - getobosobarrios@estudiantes.unsam.edu.ar
* Gianni Bevilacqua - gbevilacqua@estudiantes.unsam.edu.ar
* Javier Spina - jaspina@estudiantes.unsam.edu.ar
* Bautista Turri - Turribautista551@gmail.com

Este proyecto corresponde al trabajo pr√°ctico final de la materia **Base de Datos** de la Lienciatura en Ciencia de Datos (1er cuatrimestre 2025). Tiene como objetivo la implementaci√≥n de un sistema anal√≠tico realista utilizando un enfoque **pol√≠glota**, combinando al menos **un motor SQL** y **un motor NoSQL**. La consigna propone el dise√±o de una arquitectura de inteligencia de negocios (BI), incluyendo un Data Warehouse y la construcci√≥n de dashboards para realizar an√°lisis de datos. El trabajo integra procesos ETL, modelado dimensional de tablas, y t√©cnicas de miner√≠a de datos, simulando un caso empresarial completo.

## üß† Nuestro caso de negocio

Una compa√±√≠a tecnol√≥gica est√° desarrollando una plataforma integral basada en **dispositivos port√°tiles inteligentes**. Estas pulseras monitorean continuamente diversos **par√°metros biom√©tricos** relacionados con la salud y la actividad f√≠sica de los usuarios.  
Los dispositivos capturan datos como:  
- **Frecuencia card√≠aca**
- **Calidad del sue√±o**
- **Niveles de actividad**, entre otros.

Adem√°s, se integran con una **aplicaci√≥n m√≥vil** que permite a los usuarios:
- Interactuar y visualizar informaci√≥n
- Recibir recomendaciones personalizadas
- Gestionar sus suscripciones

Nosotros, como equipo, estamos encargados del **√°rea de datos** del proyecto. Nuestra metodolog√≠a de trabajo est√° basada en **Scrum** (metodolog√≠a √°gil), lo que nos permite iterar sobre la implementaci√≥n en ciclos de tiempo determinados.  

En una primera instancia, planeamos llegar a una versi√≥n **MVP** (*minimum viable product: m√≠nimo producto viable*) para que la empresa pueda:
- Analizar resultados
- Tomar decisiones informadas sobre el futuro del producto
- Ajustar aspectos clave del sistema y de los datos a consumir por las diferentes √°reas

El principal desaf√≠o es el **dise√±o y desarrollo de una infraestructura de datos robusta y escalable**, que pueda integrar y soportar m√∫ltiples fuentes de informaci√≥n:
- **Sistema transaccional** que gestiona suscripciones, pagos y perfiles de usuarios
- **Flujo constante y masivo (en streaming)** de los datos biom√©tricos generados por las pulseras
- **Informaci√≥n de interacci√≥n** de los usuarios con la aplicaci√≥n m√≥vil (eventos de navegaci√≥n, uso de funcionalidades, comportamiento en la plataforma)


## üßæ Requerimientos clave

La soluci√≥n que requiere la empresa implica **unificar y consolidar toda la informaci√≥n** detallada anteriormente en un **Data Warehouse** que funcione como el n√∫cleo central de an√°lisis de datos.  
Esto permite a la empresa:
- Obtener **m√©tricas clave** y **par√°metros de desempe√±o** del negocio (por ejemplo, tendencias de suscripci√≥n)
- Acceder a **patrones de uso** de las pulseras y la aplicaci√≥n
- Consultar **indicadores de salud agregados** (tanto la empresa como los usuarios)

Con esta implementaci√≥n, se contar√° con un **modelo de datos integrado** que facilitar√°:
- La generaci√≥n de **predicciones** y **modelos anal√≠ticos avanzados**
- La **optimizaci√≥n de la experiencia del usuario**
- La **mejora de la retenci√≥n**
- La **detecci√≥n de patrones de salud relevantes**
- El **respaldo a la toma de decisiones estrat√©gicas** a nivel comercial y operativo

De esta forma, se establece una **infraestructura capaz de soportar tanto an√°lisis hist√≥ricos como actuales**, y la construcci√≥n de **reportes y dashboards** que reflejen el estado y evoluci√≥n del negocio y la salud de sus usuarios.

## üß± Flujo de datos del Sistema

![Flujo de datos](./img/flujo_informacion_pulseras_inteligentes.png)

El flujo de datos de la aplicaci√≥n est√° organizado en tres subsistemas principales: **Sistema Operacional**, **Data Warehouse** y **Capa de Business Inteligence**. Cada uno de estos m√≥dulos cumple una funci√≥n espec√≠fica dentro del ecosistema de datos, y est√°n conectados mediante procesos ETL desarrollados en Python.

1. **Sistema operacional**
   Este componente gestiona toda la informaci√≥n operativa relacionada a transacciones comerciales y datos brutos de aplicaci√≥n m√≥vil y sensor de la pulsera. Se encuentra conformado por dos bases de datos:

   * **Una PostgreSQL (a trav√©s de Supabase)** que registra datos de **usuarios**, **suscripciones**, **pagos** y **estados asociados**.
   * **Y otra MongoDB** que registra los datos enviados por los **sensores de la pulsera** y la **aplicaci√≥n m√≥vil**. Aqu√≠ se registran tanto 
   las m√©tricas biom√©tricas recolectadas por las pulseras como las interacciones con la aplicaci√≥n por parte de los usuarios (como tiempo de pantalla o uso de funciones).

2. **Data Warehouse**
   Los datos operacionales son procesados mediante un flujo ETL y consolidados en un **Data Warehouse**. El objetivo 
   del mismo es guardar toda la informaci√≥n hist√≥rica del negocio para luego poder ser explotada por analistas y as√≠ mejorar continuamente el producto. El mismo se encuentra alojado en una base de datos **PostgreSQL (a trav√©s de Supabase)** la cual registra dos tipos de hechos de especial inter√©s para la compa√±ia:

   * **Hechos asociados a ventas/suscripciones del producto**.
   * **Hechos asociados a usabilidad del producto**, esto hace referencia a uso de la aplicaci√≥n por parte de los usuarios y el uso de la pulsera por igual.

3. **Capa de Business Inteligence**
   Una vez que los datos est√°n consolidados en el **Data Warehouse** estos est√°n listos para ser analizados y as√≠ obtener insights valiosos sobre el producto 
   en general. Entre los puntos clave del negocio que esta capa busca cubrir est√°n:

   * An√°lisis de ventas del producto y suscripciones a lo largo del tiempo por parte de usuarios.
   * An√°lisis de usabilidad de la pulsera y aplicaci√≥n m√≥vil en tiempo real.


## üìÇ Estructura del Proyecto

```bash
pulseras_inteligentes/
‚îú‚îÄ‚îÄ sistema_operacional/           # Sistema operacional (datos transaccionales)
‚îÇ   ‚îú‚îÄ‚îÄ ingesta_sensor_mongo/      # Scripts para ingesta de datos de sensores y aplicaci√≥n m√≥vil en MongoDB
‚îÇ   ‚îî‚îÄ‚îÄ transacciones_postgres/    # Scripts para gesti√≥n de transacciones comerciales en PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ datawarehouse/                 # Data Warehouse (Hechos de ventas y usabilidad)
‚îÇ
‚îú‚îÄ‚îÄ business_inteligence/          # Capa de Business Intelligence
‚îÇ   ‚îú‚îÄ‚îÄ dashboards/                # Dashboards de Power BI
‚îÇ   ‚îî‚îÄ‚îÄ funcionalidades/           # Funciones desarrolladas en PostgreSQL para el an√°lisis de datos
‚îÇ
‚îú‚îÄ‚îÄ utils/                         # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ conexiones_db.py           # Funciones de conexi√≥n a bases de datos
‚îÇ   ‚îî‚îÄ‚îÄ etl_funcs.py               # Funciones comunes para procesos ETL
```

## ‚öôÔ∏è Tecnolog√≠as Utilizadas

* [**PostgreSQL (via Supabase)**](https://supabase.com/) 
* [**MongoDB**](https://www.mongodb.com/) 
* [**Python (ETL y Simulaci√≥n)** ](https://www.python.org/)
* [**Power BI** ](https://www.microsoft.com/es-es/power-platform/products/power-bi)

## ‚öôÔ∏è C√≥mo clonar y correr este proyecto

### 1. Clonar el repositorio

```bash
git clone https://github.com/Gerardo1909/tp_final_pulseras_inteligentes.git
cd tp_final_pulseras_inteligentes
```

### 2. Crear y activar un entorno virtual

```bash
python -m venv venv
source venv/bin/activate      # En Linux/macOS
venv\Scripts\activate.bat     # En Windows
```

### 3. Instalar las dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar el proyecto en modo editable
Esto permite importar los m√≥dulos de `utils` desde cualquier notebook sin problemas:

```bash
pip install -e .
```



